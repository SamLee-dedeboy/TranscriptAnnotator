{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7434f48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "def count_tokens_in_messages(messages, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Count tokens in messages using tiktoken\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    total_tokens = 0\n",
    "    for message in messages:\n",
    "        # Count tokens for role and content\n",
    "        total_tokens += len(encoding.encode(message.get(\"role\", \"\")))\n",
    "        total_tokens += len(encoding.encode(message.get(\"content\", \"\")))\n",
    "        # Add extra tokens for message formatting (estimated)\n",
    "        total_tokens += 4\n",
    "\n",
    "    return total_tokens\n",
    "\n",
    "# model = \"gpt-4o-mini\"\n",
    "# for name, content in transcripts.items():\n",
    "#     encoding = tiktoken.encoding_for_model(model)\n",
    "#     current_tokens = len(encoding.encode(content))\n",
    "#     print(current_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce8cd5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "# from . import prompts\n",
    "from openai import RateLimitError, APITimeoutError\n",
    "import time\n",
    "from pydantic import BaseModel\n",
    "from typing import Dict, List\n",
    "def request_gpt(\n",
    "    client, messages, model=\"gpt-4o-mini\", temperature=0.5, format=None, seed=None\n",
    "):\n",
    "    try:\n",
    "        if format == \"json\":\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=temperature,\n",
    "                seed=seed,\n",
    "            )\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model, messages=messages, temperature=temperature, seed=seed\n",
    "            )\n",
    "        return response.choices[0].message.content\n",
    "    except RateLimitError as e:\n",
    "        print(\"RateLimitError\")\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "        return request_gpt(client, messages, model, temperature, format)\n",
    "    except APITimeoutError as e:\n",
    "        print(\"APITimeoutError\")\n",
    "        print(messages)\n",
    "        time.sleep(5)\n",
    "        return request_gpt(client, messages, model, temperature, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a467d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parseTranscript(content: str):\n",
    "    messages = []\n",
    "    lines = content.split('\\n')\n",
    "    current_message = None\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line = line.strip()\n",
    "        \n",
    "        # Check if line matches speaker pattern: [Speaker Name] hh:mm:ss\n",
    "        speaker_match = re.match(r'^\\[([^\\]]+)\\]\\s+(\\d{1,2}:\\d{2}:\\d{2})$', line)\n",
    "        \n",
    "        if speaker_match:\n",
    "            # If we were building a previous message, save it\n",
    "            if current_message:\n",
    "                messages.append(current_message)\n",
    "            \n",
    "            # Start a new message\n",
    "            current_message = {\n",
    "                'speaker': speaker_match.group(1),\n",
    "                'timestamp': speaker_match.group(2),\n",
    "                'content': \"\"\n",
    "            }\n",
    "        elif current_message and line != '':\n",
    "            # Add content line to current message\n",
    "            current_message['content'] += line + \"\\n\"\n",
    "        elif current_message and line == '':\n",
    "            # Empty line - could be end of message or just spacing\n",
    "            # We'll keep building the current message until we hit a new speaker\n",
    "            current_message['content'] += \"\\n\"\n",
    "    \n",
    "    # Don't forget to add the last message if it exists\n",
    "    if current_message:\n",
    "        messages.append(current_message)\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def messages_to_string(messages):\n",
    "    messages_str = \"\"\n",
    "    for index, message in enumerate(messages):\n",
    "        messages_str += f\"{index}: [{message['speaker']}] {message['content']}\"\n",
    "    return messages_str\n",
    "\n",
    "# Test the function with the Alex transcript\n",
    "# if 'Alex' in transcripts:\n",
    "#     parsed_messages = parseTranscript(transcripts['Alex'])\n",
    "#     messages_str = messages_to_string(parsed_messages)\n",
    "#     print(messages_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd95d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_prompt(messages_str):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a helpful assistant that segment transcripts.\n",
    "            The user will give you a transcript with indices for each message, and the criteria for segmentation.\n",
    "            You will follow the criteria to segment the transcript into sections, providing the start and end indices for each segment.\n",
    "            Reply in the following JSON format:\n",
    "            {\n",
    "                \"segments\": [\n",
    "                    {\n",
    "                        \"start_index\": <int>,\n",
    "                        \"end_index\": <int>,\n",
    "                        \"title\": \"<str>\"\n",
    "                    },\n",
    "                    ...\n",
    "                ]\n",
    "            }\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"\n",
    "            This transcript is from a user study. The study is divided into an introduction session, three scenario/task sessions, each followed by a brief questionnaire, and then a final interview session. \n",
    "            Here is the transcript:\n",
    "            {transcript}\n",
    "            \n",
    "            Please segment the transcript into sections based on the following criteria:\n",
    "            - The first segment is the introduction, where one speaker introduces the topic and procedure.\n",
    "            - The second segment is the first scenario/task session with its questionnaire.\n",
    "            - The third segment is the second scenario/task session with its questionnaire.\n",
    "            - The fourth segment is the third scenario/task session with its questionnaire.\n",
    "            - The final segment is the interview session.\n",
    "            Return the segments in the specified JSON format.\n",
    "            \"\"\".format(transcript=messages_str)\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63a64a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading transcript file: transcripts/Cars/Shasha.txt\n",
      "Reading transcript file: transcripts/Cars/Chris.txt\n",
      "Reading transcript file: transcripts/Cars/Sage.txt\n",
      "Reading transcript file: transcripts/Cars/Sebastian.txt\n",
      "Reading transcript file: transcripts/Cars/Ederson.txt\n",
      "Reading transcript file: transcripts/Cars/Sarah.txt\n",
      "Reading transcript file: transcripts/Cars/Advait.txt\n",
      "Reading transcript file: transcripts/Cars/Alex.txt\n",
      "Reading transcript file: transcripts/Cars/Ezekiel.txt\n",
      "Reading transcript file: transcripts/Cars/Ian.txt\n",
      "Reading transcript file: transcripts/Movies/Shay.txt\n",
      "Reading transcript file: transcripts/Movies/Zoe.txt\n",
      "Reading transcript file: transcripts/Movies/Jacob.txt\n",
      "Reading transcript file: transcripts/Movies/Maria.txt\n",
      "Reading transcript file: transcripts/Movies/Hailey.txt\n",
      "Reading transcript file: transcripts/Movies/Atharva.txt\n",
      "Reading transcript file: transcripts/Movies/Crosby.txt\n",
      "Reading transcript file: transcripts/Movies/Ronny.txt\n",
      "Reading transcript file: transcripts/Movies/Jian.txt\n",
      "Reading transcript file: transcripts/Movies/Jaylon.txt\n",
      "Reading transcript file: transcripts/Movies/Ina.txt\n",
      "Found 21 transcript files:\n",
      "- Shasha\n",
      "- Chris\n",
      "- Sage\n",
      "- Sebastian\n",
      "- Ederson\n",
      "- Sarah\n",
      "- Advait\n",
      "- Alex\n",
      "- Ezekiel\n",
      "- Ian\n",
      "- Shay\n",
      "- Zoe\n",
      "- Jacob\n",
      "- Maria\n",
      "- Hailey\n",
      "- Atharva\n",
      "- Crosby\n",
      "- Ronny\n",
      "- Jian\n",
      "- Jaylon\n",
      "- Ina\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from openai import OpenAI\n",
    "# read txt files from transcripts/**/*.txt\n",
    "transcript_files = glob.glob(\"transcripts/Cars/*.txt\") + glob.glob(\"transcripts/Movies/*.txt\")\n",
    "transcripts = {}\n",
    "\n",
    "for file_path in transcript_files:\n",
    "    print(f\"Reading transcript file: {file_path}\")\n",
    "    # Extract filename without extension to use as key\n",
    "    filename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Read the content of each file\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        transcripts[filename] = content\n",
    "\n",
    "print(f\"Found {len(transcripts)} transcript files:\")\n",
    "for name in transcripts.keys():\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23d5ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "responses = []\n",
    "for name, content in transcripts.items():\n",
    "    messages = parseTranscript(content)\n",
    "    messages_to_str = messages_to_string(messages)\n",
    "    prompt = segmentation_prompt(messages_to_str)\n",
    "    segmentation_response = request_gpt(client, prompt, model=\"gpt-4o-mini\", temperature=0, format=\"json\")\n",
    "    responses.append((name, messages, segmentation_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "336a31c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:14:07',\n",
       "  'content': 'Hello. Can you hear me? I can hear your voice. Hello.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:14:19',\n",
       "  'content': 'Seems like your mic is muted.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:14:29',\n",
       "  'content': 'Okay. Hi. Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:14:29',\n",
       "  'content': 'Hello? Yeah, I can… Hi. Um, so, um, are you joining through iPhone, is it?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:14:39',\n",
       "  'content': \"Yeah, because I use my, uh… Windows system made sure that I can't open the, uh, camera, so I use the iPhone.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:14:48',\n",
       "  'content': \"Okay, so, um, cause, uh, later I'll provide you the, like, the account, the files, the data set through.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:14:56',\n",
       "  'content': 'Zoom chat, so… Is it possible for you to do it through the… computer, your laptop, or something.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:15:07',\n",
       "  'content': \"Um, we'll try…\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:08',\n",
       "  'content': 'Or do I need to send it through, um, email to you?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:15:12',\n",
       "  'content': \"Yeah, emails, okay, I don't know. If I use my computer, there's no voice, and uh… We do.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:22',\n",
       "  'content': \"Okay, okay, sounds good. Okay, we'll figure it out, no worries.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:15:27', 'content': '1.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:27',\n",
       "  'content': 'Okay, so, first of all, thank you so much for participating in the study, and later on… Um, and let me share my screen first.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:36',\n",
       "  'content': \"So, if you can see my screen right now, um… Later, what we're… we will be doing is I'll read you through the.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:44',\n",
       "  'content': \"letter of information here, and then I'll show you the demo process of the study.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:49',\n",
       "  'content': 'And then we would go straight into the study process.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:54',\n",
       "  'content': 'So, is it okay for you to, um, look at the.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:15:58',\n",
       "  'content': \"screen here that I'm sharing right now. Okay. Okay, so I'll just go ahead and read through the letter of information, and if you have any questions, just interrupt me and I'll answer you right away.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:16:02',\n",
       "  'content': 'Yes, I can see.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:12',\n",
       "  'content': 'Okay, so for the letter of information here, our topic is ambiguities in AI-generated visualization.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:18',\n",
       "  'content': 'And the purpose is that later you will be asked to use a AI system, which is ChatGPT, to explore a dataset.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:26',\n",
       "  'content': 'To generate visualizations using natural language prompts, describe your insights from the chart, rate their clarity and usefulness, and complete a short interview about your experience.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:35',\n",
       "  'content': 'And the whole procedure should take about, um, 60 minutes, which is.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:40',\n",
       "  'content': 'Um… wait. Are you joining through another device?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:16:46',\n",
       "  'content': 'Yeah, I use my computer. Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:48',\n",
       "  'content': 'Okay, no worries. So, can you see it right now?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:16:52',\n",
       "  'content': 'Okay. Okay. Hmm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:16:53',\n",
       "  'content': 'Okay, sounds good. So, um… What did I… yeah, so the whole visitors, it takes about an hour, which is 16 minutes.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:01',\n",
       "  'content': \"And later, when you're doing a study, the screen will be recorded when you see the tool. The screen recorders are used only to verify task completion interaction behavior with the AI system.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:11',\n",
       "  'content': 'And the audio will be recorded during the interview session, and you will be transcribed for analysis.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:16',\n",
       "  'content': 'But any information, like your name and any principal information will not be included in the transcription.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:21',\n",
       "  'content': 'So, do you have any questions regarding the letter of information here?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:17:25',\n",
       "  'content': 'Uh, no questions.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:27',\n",
       "  'content': \"Okay, so I'll go ahead to share another screen again to show you the.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:32',\n",
       "  'content': 'demo process here, and just give me one moment…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:40',\n",
       "  'content': 'Okay, can you see my screen right now? Okay, so have you used ChatGPT before?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:17:43',\n",
       "  'content': 'Yeah. Yes, yes.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:48',\n",
       "  'content': \"And I bet that you're quite familiar with the system.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:17:51',\n",
       "  'content': \"And later, what we'll be doing is that I'll provide you the, um… Login information to the ChatGPT account, so you'll be using our ChatGPT account.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:02',\n",
       "  'content': \"By logging in through the Gmail and password, and after that, you'll see an interface like this.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:07',\n",
       "  'content': \"And then I'll also provide you a dataset file and a scenario file.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:12',\n",
       "  'content': \"So, basically, what we're going to do with the DSF file is you just need to download it and, like, drag it in to ChatGPT to upload it.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:20',\n",
       "  'content': \"Or you can use the add button here as well. Just do whatever you're familiar with.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:18:21', 'content': 'Mm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:24',\n",
       "  'content': \"And in this case, we have successfully uploaded, and you don't need to send it right away. You can go back to the scenario file and start reading.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:32',\n",
       "  'content': 'And basically, what a scenario file is, is it includes a paragraph of introduction of that dataset.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:39',\n",
       "  'content': 'We are also, um, free to, like. open up the DSFO to observe yourself, but this paragraph is just basically a small paragraph for you to get familiar with it.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:48',\n",
       "  'content': \"And then you'll see 3 visualization scenarios, and what a scenario is, it's basically what.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:18:54',\n",
       "  'content': 'The things that are most important here for today. Um… After you read this, you have to put yourself in that scenario and try to generate a visualization that can fit the scenario and.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:06',\n",
       "  'content': 'You can get the ideal visualization for. So basically, for example, for this scenario.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:12',\n",
       "  'content': 'Imagine your original sales analysis is about to brief your team. Use the data set to show which regions are performing well and which might need improvement.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:19',\n",
       "  'content': 'How would you visualize the differences in total sales and profit to make your story convincing?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:24',\n",
       "  'content': 'So basically, after the introduction, you can know that the JSet is for a super source.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:31',\n",
       "  'content': 'And it includes some things like data ship, sales forecasts, SHIP status.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:36',\n",
       "  'content': 'Categories, cities, countries, something like that. And after I put myself in this scenario.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:41',\n",
       "  'content': \"I'll start to think of what should I prompt to chat GPT to get my ideal visualization?\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:46',\n",
       "  'content': \"So I'll probably prompt like this. please generate… A visualization.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:19:53', 'content': 'Mm-hmm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:19:54',\n",
       "  'content': \"Emphasizing total cells and profits. In different… Regions. Okay, so that's what I get from the scenario, because it's asking.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:07',\n",
       "  'content': \"Which regions are performing well, which my name proven and differences in total sales and profits, right? So that's what I get.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:14',\n",
       "  'content': \"Now I'll just send it, and wait for its generation.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:17',\n",
       "  'content': 'And it might take a little while.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:40',\n",
       "  'content': 'Okay, so basically, this is the chart generated by ChatGPT for me.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:45',\n",
       "  'content': 'And the next step for you will be you will start to think about if this chart satisfies you or not.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou', 'timestamp': '15:20:51', 'content': 'So if\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:20:55',\n",
       "  'content': 'to, um, prompt more… Um, ratings to ChatGPT to asset to improve or modify the chart for you.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:01',\n",
       "  'content': 'So, um, maybe you can ask to change a.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:05',\n",
       "  'content': 'Um, craft style to modify the colors for you, to modify the units for you, the access for you.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:12',\n",
       "  'content': 'Anythings you want, just interact freely with ChatGPT and take your time.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:16',\n",
       "  'content': \"And whenever you're ready. Um, whenever you think that the chart already satisfies you, just let me know, and we will go directly to the survey, and I'll provide you the survey link.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:21:28',\n",
       "  'content': \"Ah… I'm ready.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:28',\n",
       "  'content': 'Yes, yes, sorry. Okay.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:21:34', 'content': 'Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:35',\n",
       "  'content': 'Okay, so, uh, for the survey, um, as mentioned here, you have to put down your 3 to 5 insights here.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:42',\n",
       "  'content': 'So what an insight is, is what you actually observe from the visualization here, and how can it answer the scenario questions.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:21:49',\n",
       "  'content': 'So, for example, I would type in, um, the… insights like this, that the West region has the highest sales and profits, and I believe it performs the best.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:00',\n",
       "  'content': 'And the south region needs improvement the most. And I believe the sales and profits are positively correlated.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:06',\n",
       "  'content': \"These can all be the insights, because that's the thing that you observe from visualizations, and can answer the questions of the scenario.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:14',\n",
       "  'content': \"But please don't put in the insights, like, um.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:18',\n",
       "  'content': 'Uh, I prompt to ChatGPT, and it gave me some inconsistent, um.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:22',\n",
       "  'content': 'topic, uh, some inconsistent visualizations, and I asked. for modification. For those, like, the fillings, like… the feelings that you interact with ChatGBT. This can be answered after the survey questions and the interview.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:36',\n",
       "  'content': 'So, for the insights, please just put in the ones that you observed from the visualization.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:41',\n",
       "  'content': 'And after your 3G5 in science, you will fill in the survey, and we will have a really, really short interview for each scenario.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:48',\n",
       "  'content': \"So basically, we'll do it for 3 times, and then we will go ahead to the last part of the survey and the interview.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:22:54',\n",
       "  'content': \"And that's the end of today. So, do you have any questions regarding, um, the study right now?\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:23:01',\n",
       "  'content': 'Uh, 22,000 images from.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:07',\n",
       "  'content': \"Oh, no, you don't need to download the images, just let me know that which, um, graph.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:12',\n",
       "  'content': \"Which visualization is the ideal one to you, then that's enough.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:23:15',\n",
       "  'content': 'Okay, okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:15',\n",
       "  'content': \"Okay, so right now… I'll go ahead to send the.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:21',\n",
       "  'content': 'information that you need through the Zoom chat to you.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:27',\n",
       "  'content': \"Can you see it? Okay, so basically what you need to do is to log in through the ChatGPT account, and whenever you're ready, please share your screen with me so we can go through the process together.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:23:28',\n",
       "  'content': 'Yeah. Yeah, yeah.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:23:48',\n",
       "  'content': 'It was the most amazing thing. Right, right, right.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:50',\n",
       "  'content': 'Yeah, and please, um, log out of your own account first, and log in through my account.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:23:56',\n",
       "  'content': 'Oh, no problem.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:23:59',\n",
       "  'content': 'Mm-hmm. Um, so if you want to log out, you may need to, um… Um, go to the left lower corner.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:24:11',\n",
       "  'content': 'Left bottom corner and. Um…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:24:22',\n",
       "  'content': 'Okay, so let me show you through my screen.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:24:25',\n",
       "  'content': 'Wait a second… Okay, so if you can see my screen right now.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:24:33',\n",
       "  'content': 'Uh, if you want to log out, you should click on… Here is the button of your account, yeah, and there is a lockout button.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:24:37', 'content': 'Oh.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:24:48', 'content': 'Nice.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:24:56',\n",
       "  'content': 'Um, could you please open the full screen, and we will see.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:25:11',\n",
       "  'content': 'Yeah. No.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:16',\n",
       "  'content': 'Um… Weird…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:25:18',\n",
       "  'content': 'Your trip.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:27',\n",
       "  'content': \"Or could you, um… Let's see…\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:35',\n",
       "  'content': 'Um, could you please click the upper right corner? There is a full screen, the square button here.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:41',\n",
       "  'content': 'Um, let me check a little bit. The right, right, on the right.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:45',\n",
       "  'content': \"Right upper corner. Uh, no, there's a square above.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:25:48',\n",
       "  'content': 'But, uh, check here.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:51',\n",
       "  'content': \"for a full screen, I just want to check if there's.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:25:55',\n",
       "  'content': 'Anything lower.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:26:08',\n",
       "  'content': 'Oh, okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:26:09',\n",
       "  'content': \"Oh yeah, yeah, yeah, yeah, that's what I mean, yeah.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:26:11',\n",
       "  'content': 'Exactly, exactly. Okay, then you can log into another account and continue with Google.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:26:21',\n",
       "  'content': \"Yes, and you can type in… The account that I… oh, wait, what's happening?\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:26:29',\n",
       "  'content': \"I don't know why. Well, I haven't really calm, Tom.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:26:35',\n",
       "  'content': 'Ah, okay, then just basically do it again.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:26:38',\n",
       "  'content': 'So, log in…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:26:51',\n",
       "  'content': 'Why is it happening?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:27:05',\n",
       "  'content': \"That's so weird, oh my goodness, um. Let's see…\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:27:19',\n",
       "  'content': 'Um… could you please, yeah, put in the email address directly here?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:27:24', 'content': 'Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:27:25',\n",
       "  'content': 'Let me check if it works or not.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:28:15', 'content': 'Oh.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:28:24',\n",
       "  'content': 'Or there is another way, if you want to.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:28:29',\n",
       "  'content': \"Open a private window for me. It may work, because it's not logged in.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:28:37',\n",
       "  'content': \"I try to log out my Google account. I can't do that.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:28:44',\n",
       "  'content': \"Um, okay, it's okay, we can solve it together, and… Um, could you please share the screen again? Because it's disconnected.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:28:56',\n",
       "  'content': 'Okay, so, um… Could you please.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:03',\n",
       "  'content': 'Um… do you know how to open a private web page of Google?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:29:11',\n",
       "  'content': \"Uh, no, I don't know.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:15',\n",
       "  'content': 'Um, so, um, can you, uh, move to the Chrome.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:19',\n",
       "  'content': 'Um… Chrome icon on the left.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:24',\n",
       "  'content': 'Lower corner. The left lower corner.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:32',\n",
       "  'content': \"There's a Chrome, right? Yeah, yeah, yeah, yeah. Can you just move to the icon there?\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:29:32', 'content': 'Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:47',\n",
       "  'content': 'Um, the lower… Yeah, there is… there is a Google Chrome icon, right?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:29:51',\n",
       "  'content': 'Nothing.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:29:56',\n",
       "  'content': 'No, yeah, this one.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:29:58',\n",
       "  'content': \"Yeah. Yeah, can you click it, uh, by your right, um… And there's a new, uh, incognito window.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:30:07', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:07',\n",
       "  'content': \"Yeah, can you use this to open ChatGPT, please? It shouldn't… I'll be logged in, in this case.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:13',\n",
       "  'content': 'Yeah, and click login again. And use the account that I provided.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:20',\n",
       "  'content': 'Yeah, and it works.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:30:23',\n",
       "  'content': 'So I can.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:26',\n",
       "  'content': 'Yeah, just paste the Gmail that I provided you.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:30',\n",
       "  'content': 'Oh, no, no, no, no, not this one. I did, uh, send you through the Zoom chat, right?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:41',\n",
       "  'content': 'The AI Genvidstudy at gmail.com, this one.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:30:51',\n",
       "  'content': 'Oh, which, which one is…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:30:57',\n",
       "  'content': 'No, no, no, no, no, no, this one. I sent it again.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:31:01',\n",
       "  'content': 'Hmm. Yeah. Yeah, yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:31:02',\n",
       "  'content': 'Can you see that? Just paste the Gmail.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou', 'timestamp': '15:31:07', 'content': 'Here.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:31:43',\n",
       "  'content': 'Okay. Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:31:45',\n",
       "  'content': \"Okay, and right now you're logged in. And you can upload the dataset file here, and open up your scenario file.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:31:54',\n",
       "  'content': 'And start reading.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:01',\n",
       "  'content': 'Yes, and the scenario file is in the chat also.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:05',\n",
       "  'content': 'Can open it up and start browsing introduction and scenario 1.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:32:11',\n",
       "  'content': 'Uh, okay, the Excel?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:16',\n",
       "  'content': 'And… No, no, no, no, no, no, no, no, no, wait, wait, um… Um, okay, let me… show you right here.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:27',\n",
       "  'content': 'If you can see my screen right now. I sent you a Your Scenario file here, right?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:32:35', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:35',\n",
       "  'content': 'Yeah, just open it up. And it will link you to your scenario file, and you just need to read the introduction, and the very first scenario.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:45',\n",
       "  'content': 'And to prompt to ChatGPT.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:50',\n",
       "  'content': \"Is that… is that clear for you? Yeah, so, um, if you're ready, you can just open it up. I can send it again.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:32:52', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:32:59',\n",
       "  'content': 'And just click it, click the link, and you can see it.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:33:12',\n",
       "  'content': 'Yeah, like I said.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:33:14',\n",
       "  'content': 'Okay, so…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:33:17',\n",
       "  'content': 'The first one, plus…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:33:22',\n",
       "  'content': 'Um, did you open up the scenario file? Okay, so, um… Do you want to open it through… Your laptop or through cell phone is okay?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:33:25', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:33:34',\n",
       "  'content': 'Oh, I slow my, uh, computer.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:33:38',\n",
       "  'content': 'On your computer? Okay. So, um, yeah, you can start reading introduction and the scenario 1.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:33:45',\n",
       "  'content': 'And whenever you are ready to prompt for… to get your visualization for Scenario 1, you can go back to ChatGPT and start prompting.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:33:52',\n",
       "  'content': 'Hmm. Uh, yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:33:53',\n",
       "  'content': \"Is that clear for you? Okay, so just let me know if you need any help, and I'll just leave the time for you.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:34:46',\n",
       "  'content': 'Just as the, uh, test one now, right?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:34:51',\n",
       "  'content': 'Yeah, exactly\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:36:15',\n",
       "  'content': 'Just a reminder that your ultimate goal for every scenario is to get a visualization.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:36:22', 'content': 'Okay…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:37:10',\n",
       "  'content': \"So, what's the… Imagine Tom make its name.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:37:17',\n",
       "  'content': \"I'm sorry?\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:37:19',\n",
       "  'content': 'Uh, I think you should have you use which.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:37:25',\n",
       "  'content': 'Do you think is correct? Shows it.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:37:30',\n",
       "  'content': \"Um… I don't quite get what you mean. Can you say that again?\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:37:42',\n",
       "  'content': \"Um, so, um, so basically, there's no right or wrong here in the study, you just can't… you can interact freely with ChatGPT as you want, so… Don't worry about if it's right or wrong.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:37:57',\n",
       "  'content': 'Oh, but…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:38:09',\n",
       "  'content': 'Yeah, is there anything you want to ask?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:38:13',\n",
       "  'content': 'January cancer, I imagine. I kind of go to it.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou', 'timestamp': '15:38:23', 'content': 'Hmm…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:38:31',\n",
       "  'content': 'So, basically? Again, as I just said.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:38:36', 'content': 'Mm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:38:37',\n",
       "  'content': 'Our ultimate goal is to get a visualization. from ChatGPT.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:38:43',\n",
       "  'content': \"So if you're asking that… While you're getting an image instead of visualization, because you're prompting with, um.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:38:51',\n",
       "  'content': 'Image, not visualization. So…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:38:56',\n",
       "  'content': \"Uh-oh. It's not imaging, sorry.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:42:53',\n",
       "  'content': 'No. Hello. Yeah, I can hear you now.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:42:56',\n",
       "  'content': 'Go ahead. It loves images, too.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:43:03',\n",
       "  'content': \"I can't say anything.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:43:06',\n",
       "  'content': 'Yeah, so, um… I mean, is that your ideal chart for you?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:43:14',\n",
       "  'content': 'Yeah. Yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:43:15',\n",
       "  'content': \"This one? Okay, so you're ready for the survey process, is that?\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:43:23', 'content': 'Hmm?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:43:29',\n",
       "  'content': 'I sent the survey through the chat. And you can open it up for me.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:43:35',\n",
       "  'content': 'Through the same, um. Um, just open it up here for me.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:43:40',\n",
       "  'content': 'That we can see.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:43:41', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:44:08',\n",
       "  'content': \"Yeah, I'm typing.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:44:11',\n",
       "  'content': \"Um, but I cannot see what you're typing right now.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:44:17',\n",
       "  'content': 'Cool. I have 2 screen case now.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:44:22',\n",
       "  'content': 'Yeah, you can see it right now. Looks good, and yeah.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:46:44',\n",
       "  'content': 'I finished the test. 1.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:46:47',\n",
       "  'content': 'Okay, so, um, can you… let me take a look at your insights first?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:46:54',\n",
       "  'content': 'Can I repeat it? Hmm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:46:55',\n",
       "  'content': \"Oh, no, no, no, above the survey. There's the insights that I just typed.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:01',\n",
       "  'content': 'Right. Okay, so.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:47:02', 'content': 'Yeah.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:08',\n",
       "  'content': 'Um, this is actually what we do not consider as insights, so as I told you, insights should be the.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:16',\n",
       "  'content': 'observation you get from the visualization, and how can it answer back to the scenario questions.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:29',\n",
       "  'content': 'So, from what I told you, from my demo example.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:33',\n",
       "  'content': \"For example, I can tell that, like, two X's are positive correlated.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:47:34', 'content': 'Mm-hmm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:39',\n",
       "  'content': 'Or which regions perform the best, which regions need the most improvement, that can be called insights.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:46',\n",
       "  'content': 'But the things that you type right now is not actually in sites.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:47:50',\n",
       "  'content': 'So, could you please modify it for me?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:47:54',\n",
       "  'content': 'Okay… So, I forgot your sample closely to me.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou', 'timestamp': '15:48:01', 'content': 'Sorry?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:48:03',\n",
       "  'content': \"I've got what your sample shows. Uh…\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:48:09',\n",
       "  'content': \"Um, but my sample is different from you. I'm just letting you know that what can be counted as insights, but this is.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:48:13',\n",
       "  'content': 'Um… Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:48:15',\n",
       "  'content': 'Yeah, so just… Mainly to modify it for you, or you can take a look back to the scenario file that what is it actually asking.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:48:23',\n",
       "  'content': 'That may help.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:48:41',\n",
       "  'content': 'Oh, how performance?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:48:58',\n",
       "  'content': \"Um, sorry, are you… Um, taking a look at the other… Oh, please, please don't do that, thank you. Please.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:49:02',\n",
       "  'content': \"I think it's very different. Oh, sorry.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:49:10',\n",
       "  'content': 'And, uh, another hotel shows. Yellow Children… But I only have one chart, is it okay?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:49:22',\n",
       "  'content': 'Or I should modify and then do the inside.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:49:27',\n",
       "  'content': \"Um, so what we want is… One chart, one ideal chart, that's.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:49:33',\n",
       "  'content': \"Satisfy you through the scenario, that's what we want.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:49:34',\n",
       "  'content': 'Hmm. Okay, because this is…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:49:58', 'content': 'Hmm…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:51:36',\n",
       "  'content': \"That's how…\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:52:04',\n",
       "  'content': 'Like this?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:52:08',\n",
       "  'content': 'Okay, okay, looks good, and um. Um… We are going to move on to a short interview for the questions that you just answered.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:52:19',\n",
       "  'content': 'So, um, could you please tell me that, uh, for the first question.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:52:23',\n",
       "  'content': 'The chart is clear and easy to understand why you select 2, which is slightly.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:52:30',\n",
       "  'content': 'And, um, what made it easy or difficult for you to understand?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:52:35',\n",
       "  'content': \"I think it's not very easy because. It not how I must.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:52:46',\n",
       "  'content': \"Uh… Judge which one have the best balance by myself, I think it's not very visible.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:52:54',\n",
       "  'content': 'Because a lot of models, almost the same in the chart.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:01',\n",
       "  'content': \"So, so I think it's slightly.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:53:05',\n",
       "  'content': 'Okay, and could you please scroll it down a little bit for me?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:53:09', 'content': 'Mm.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:53:14',\n",
       "  'content': 'Um, okay, and… Um, for the insights that you just typed, can you talk a little bit about your insights for me?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:23',\n",
       "  'content': 'Ah, my U.S.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:53:25',\n",
       "  'content': 'Yeah, can you talk a little bit about it?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:29',\n",
       "  'content': \"Uh, yeah. I think it's the… that some 2800X from the chart.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:38',\n",
       "  'content': \"But I think it's. This note is the best.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:43',\n",
       "  'content': \"is just the balance, I think it's better, but.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:53:48',\n",
       "  'content': \"For the horsepower and MPG. Uh… It's not a very good.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:54:00',\n",
       "  'content': \"But I don't know how very much, it's just.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:54:06',\n",
       "  'content': 'May I understand. from the chat.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:08',\n",
       "  'content': 'Okay. Okay, sounds good. Yeah.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '15:54:13', 'content': 'Bye.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:14',\n",
       "  'content': 'Uh, I guess we can move on to the second scenario, and for the second scenario, please open a new chat for me.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:21',\n",
       "  'content': 'At ChatGPT, and um… Do you know how to open up a new chat here?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:54:30',\n",
       "  'content': 'Yeah. Hmm… Oh.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:33',\n",
       "  'content': \"There's a new chat button above.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:41',\n",
       "  'content': 'Yeah, and just upload the same data set again.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:54:45',\n",
       "  'content': 'And you can start reading Scenario 2.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:57:46',\n",
       "  'content': 'I get the chart. But I… it can show in the chat GPT. I downloaded it.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:57:55',\n",
       "  'content': 'Can you refresh the page for me?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:58:03',\n",
       "  'content': \"Yeah, it's okay.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '15:58:26',\n",
       "  'content': 'So, to the survey?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '15:58:30',\n",
       "  'content': 'Yeah, if you feel like it satisfies you, you can go type in your insights and answer your survey questions.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:02:43',\n",
       "  'content': 'Yeah, finish the… Patrick.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:02:47',\n",
       "  'content': 'Okay, and, um, same as the one above, could you please talk a little bit about your insights first?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:02:56',\n",
       "  'content': 'Uh, this chatter is very easy. To read but from my margin, I see the.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:03:06',\n",
       "  'content': 'increase in Europe and Japan is very similar. is different to the USA, but the increase.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:03:15',\n",
       "  'content': \"Oh, the US is very fast, but. It's a start point is very low.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:03:22',\n",
       "  'content': 'So, uh, in the… Endpoint is still lower than Japan and Europe.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:03:32',\n",
       "  'content': 'Okay, I see, and for the survey that you just answered.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:03:37',\n",
       "  'content': 'Can I take a look? Okay, so, uh, for the question that I am not concerned that the AI-generated chart may misrepresent the dataset.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:03:49',\n",
       "  'content': 'You select moderately. Can you tell me the reason on that?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:03:54',\n",
       "  'content': \"Uh… I'm not too sure… It's real not, but I only want to know the change totally change.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:04:09',\n",
       "  'content': \"So, sometimes I think I'm not concerned. Uh, to say.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:04:17',\n",
       "  'content': 'Mm-hmm.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:04:19',\n",
       "  'content': \"Maybe it's okay, really.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:04:23',\n",
       "  'content': \"Maybe it's okay.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:04:28',\n",
       "  'content': 'Um, okay. Um, so for… Um, the question?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:04:34',\n",
       "  'content': 'I am confident in my own interpretation of the chart.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:04:38',\n",
       "  'content': 'You select 4, which is very. Um, can you tell me the reason on that?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:04:45', 'content': 'Uh…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:04:49',\n",
       "  'content': 'I think the child is very easy. To read, so I choose very.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:04:56',\n",
       "  'content': 'Uh, idols extremely is because. Uh, in the increase, sometimes it has some.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:05:07',\n",
       "  'content': \"Very small, uh… Like, like, sometimes it's decrease.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:05:14',\n",
       "  'content': \"Uh, so from the chart, we can't know very well, uh, everything, so I chose very, not extremely.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:05:25',\n",
       "  'content': 'Okay, I see, and I guess we can move on to the very last scenario.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:05:31',\n",
       "  'content': 'And as the one, uh, mentioned. In scenario 2, please open a new chat and upload the JST again for me.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:05:40', 'content': 'Okay…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:10:21',\n",
       "  'content': 'I think I finished this pal.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:10:24',\n",
       "  'content': 'Okay, so go ahead to your Insights and survey questions.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:13:27',\n",
       "  'content': 'I finished the…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:13:29',\n",
       "  'content': 'Okay. So, again, could you please talk a little bit about your insights?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou', 'timestamp': '16:13:34', 'content': 'First.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:13:37',\n",
       "  'content': 'Uh, because this task is compares. different in three regions. I, I think the Europe and Japan still.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:13:50',\n",
       "  'content': \"How the same performance. Uh, so… house power and MPG, and USA, the hospital is very higher than those, uh, the other 2 regions, so it's very different to other two regions.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:14:10',\n",
       "  'content': \"Uh, and, uh, is MPJ is lower. Uh, but not too much, so I think people in USA, it's like.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:14:22',\n",
       "  'content': 'hire horsepower. Cause…\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:14:26',\n",
       "  'content': 'Okay… Um, so for the answers… that are provided. Um… The fourth question, the chart is helpful in answering the question or understanding the data set.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:14:41',\n",
       "  'content': 'You select moderately. Can you tell me the reason on that?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:14:46',\n",
       "  'content': 'Uh, I think the chart is only summarize some, like, the average.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:14:55',\n",
       "  'content': \"but I, I think the it's, it's is. Ingenar, some special models.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:15:08',\n",
       "  'content': \"So, it can show… So, uh… Generally, to show this difference, but it's, it's not.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:15:18',\n",
       "  'content': \"All the CCs have some important information can't get from the chart.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:15:28',\n",
       "  'content': 'Okay, um, then I guess we can move on to the last part. Could you please click the arrow for me?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:15:37',\n",
       "  'content': \"Yeah, and again. Yeah, please answer the questions and let me know when you're finished and don't send it out first.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:16:26',\n",
       "  'content': 'Yeah, I submit it.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:16:27',\n",
       "  'content': 'Can you send it out already? Okay. Um, so… I want to ask you a few questions.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:16:35', 'content': 'Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:16:35',\n",
       "  'content': 'Hmm. About the answers that you just provided. So, the first question is asking you the faithfulness, right? Just want to, uh, know what actually helped or limited your sense of faithfulness.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:16:48', 'content': 'Uh…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:16:52',\n",
       "  'content': \"I think it's good. But, uh… For me, it's have some difficulties is… Because, uh… because I don't know the cost.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:07',\n",
       "  'content': \"So. It's hard for me to.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:13',\n",
       "  'content': 'To know how to get the. try to clearly to get my questions.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:20',\n",
       "  'content': \"Uh, sometimes I… maybe the first time I get a chart, I think it's.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:28',\n",
       "  'content': \"Can't ask them a question, but it's because I can't have a very.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:34',\n",
       "  'content': \"Uh, very, uh, very good questions for the. AI, so maybe it's not the AI's problem, but it's for my knowledge problem.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:17:48',\n",
       "  'content': \"Uh, but totally, I think it's… I think it's a good.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:17:55',\n",
       "  'content': 'Okay, sounds good. And was there anything about AI interface or responses that made it easier or harder for you to use?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:18:03',\n",
       "  'content': \"Mmm… I think it's easier for me. Uh, we are spending some time to practice.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:18:13',\n",
       "  'content': 'Okay. Okay, the next question is that, um, how did you react or handle the situations when tragedy gave you some inconsistent or confusing outputs?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:18:26',\n",
       "  'content': 'Sometimes I repeat my question. And uh…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:18:35',\n",
       "  'content': 'Sometimes, maybe not ask the final question. Just ask some.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:18:43',\n",
       "  'content': 'Individual steps. This is what I did before.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:18:52',\n",
       "  'content': 'Okay, and um… For the next question, can you tell me how to decide when to trust or when to question the charts generated by the AI?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:19:03',\n",
       "  'content': 'Uh, sorry, sorry.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:19:05',\n",
       "  'content': 'Um, how do you decide when to trust or when to question the charts generated by the AI?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:19:13',\n",
       "  'content': \"Hmm… I think it's based on the question.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:19:20',\n",
       "  'content': \"If it's for my work. I will double check.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:19:25',\n",
       "  'content': \"But it's only for my life. Like, buying something.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:19:31',\n",
       "  'content': 'Uh, and, uh, chores… Some place to travel, those not work since I will trust.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:19:41', 'content': 'So, AI.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:19:43',\n",
       "  'content': 'Hmm, okay, and uh… Um, for the question that do you trust the AI tool to generate accurate and reasonable visualizations?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:19:54',\n",
       "  'content': 'Um, can you tell me what would make you to trust it even more?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:19:59', 'content': 'Um…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:20:06',\n",
       "  'content': 'For… for the chart from the AI.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:20:13',\n",
       "  'content': \"I can't trust… So… Some… I think I always… do by myself again.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:20:27',\n",
       "  'content': \"Actually, I'm not very trusted to. Doc.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:20:33',\n",
       "  'content': \"It's a chart.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:20:33',\n",
       "  'content': 'Mm-hmm. Okay, and for the last questions, uh, last two questions was, uh, I just want to ask.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:20:43',\n",
       "  'content': \"The question's back to you after you use the system.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:20:46',\n",
       "  'content': 'So, thinking back on the whole session, can you tell me how confident do you feel about interpreting AI-generated visualizations right now?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:20:55',\n",
       "  'content': \"Uh… I… I think, uh… From my understanding, it's very curious.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:21:03',\n",
       "  'content': \"Only the task one, I'm not very sure, but for the task 2 and 3.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:21:11',\n",
       "  'content': 'I think it was works very good. I can easily get the.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:21:17',\n",
       "  'content': 'Information was what I want. But for the Task 1.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:21:25',\n",
       "  'content': \"Hmm… it's difficult. And I have no confidence to the question.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:21:34',\n",
       "  'content': 'Okay, and last question. What stood out to you the most about the AI strengths or weaknesses in visualization?\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:21:41',\n",
       "  'content': 'And if you were to use a similar tool in your own work or study, what would you hope to improve or keep the same?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:21:49', 'content': 'Mmm…\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:21:55',\n",
       "  'content': 'I… sometimes I… I want it can provide some.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:02',\n",
       "  'content': 'Like, uh, some frames, it can also show me.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:08',\n",
       "  'content': 'How, uh, which, which chat. I can get the answers.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:15',\n",
       "  'content': 'Not just. Maybe the first step, it can, uh, get some.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:22',\n",
       "  'content': 'Uh, suggestions… Uh, do you want 1 1 2 3 and give me a choice?\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:30',\n",
       "  'content': 'And I chose one or two or three, and then the best are on my next question to.\\n\\n'},\n",
       " {'speaker': 'iPhone (50)',\n",
       "  'timestamp': '16:22:38',\n",
       "  'content': 'Generators chart.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:22:41',\n",
       "  'content': \"Hmm… okay, I see, and I guess that's the end of.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:22:47',\n",
       "  'content': \"Today's study and thank you so much for participating, and your next step will be logging out.\\n\\n\"},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:22:54',\n",
       "  'content': \"of ChatGPT, and uh. Yeah, and… That's the end for today's study, and if you have any questions regarding the study or regarding the compensation, you can email me and I'll reply to you as soon as possible.\\n\\n\"},\n",
       " {'speaker': 'iPhone (50)', 'timestamp': '16:22:55', 'content': 'Okay.\\n\\n'},\n",
       " {'speaker': 'Chifang Chou',\n",
       "  'timestamp': '16:23:11',\n",
       "  'content': 'And for the Amazon gift card, it will be sent out to you through email\\n\\n\\n'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16ba9856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segments': [{'start_index': 0, 'end_index': 31, 'title': 'Introduction'},\n",
       "  {'start_index': 32, 'end_index': 82, 'title': 'First Scenario/Task Session'},\n",
       "  {'start_index': 101,\n",
       "   'end_index': 301,\n",
       "   'title': 'Second Scenario/Task Session'},\n",
       "  {'start_index': 302,\n",
       "   'end_index': 373,\n",
       "   'title': 'Third Scenario/Task Session'},\n",
       "  {'start_index': 374, 'end_index': 376, 'title': 'Interview Session'}]}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_response = json.loads(responses[0][2])\n",
    "segmentation_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b051e944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'segments': [{'start_index': 0, 'end_index': 31, 'title': 'Introduction'}, {'start_index': 32, 'end_index': 83, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 268, 'end_index': 301, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 302, 'end_index': 373, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 374, 'end_index': 376, 'title': 'Interview Session'}]}\n",
      "Transcript: Shasha\n",
      "Transcript: Shasha\n",
      "Transcript: Shasha\n",
      "Transcript: Shasha\n",
      "Transcript: Shasha\n",
      "{'segments': [{'start_index': 0, 'end_index': 19, 'title': 'Introduction'}, {'start_index': 20, 'end_index': 66, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 188, 'end_index': 201, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 232, 'end_index': 275, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 278, 'end_index': 356, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Chris\n",
      "Transcript: Chris\n",
      "Transcript: Chris\n",
      "Transcript: Chris\n",
      "Transcript: Chris\n",
      "{'segments': [{'start_index': 0, 'end_index': 62, 'title': 'Introduction'}, {'start_index': 63, 'end_index': 59, 'title': 'First Scenario/Task Session'}, {'start_index': 162, 'end_index': 229, 'title': 'Second Scenario/Task Session'}, {'start_index': 230, 'end_index': 358, 'title': 'Third Scenario/Task Session'}, {'start_index': 359, 'end_index': 362, 'title': 'Interview Session'}]}\n",
      "Transcript: Sage\n",
      "Transcript: Sage\n",
      "Transcript: Sage\n",
      "Transcript: Sage\n",
      "Transcript: Sage\n",
      "{'segments': [{'start_index': 0, 'end_index': 85, 'title': 'Introduction'}, {'start_index': 86, 'end_index': 83, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 175, 'end_index': 219, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 220, 'end_index': 270, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 271, 'end_index': 354, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Sebastian\n",
      "Transcript: Sebastian\n",
      "Transcript: Sebastian\n",
      "Transcript: Sebastian\n",
      "Transcript: Sebastian\n",
      "{'segments': [{'start_index': 0, 'end_index': 60, 'title': 'Introduction'}, {'start_index': 61, 'end_index': 108, 'title': 'Scenario 1 and Questionnaire'}, {'start_index': 122, 'end_index': 201, 'title': 'Scenario 2 and Questionnaire'}, {'start_index': 188, 'end_index': 266, 'title': 'Scenario 3 and Questionnaire'}, {'start_index': 226, 'end_index': 286, 'title': 'Final Interview'}]}\n",
      "Transcript: Ederson\n",
      "Transcript: Ederson\n",
      "Transcript: Ederson\n",
      "Transcript: Ederson\n",
      "Transcript: Ederson\n",
      "{'segments': [{'start_index': 0, 'end_index': 68, 'title': 'Introduction'}, {'start_index': 69, 'end_index': 135, 'title': 'First Scenario/Task Session'}, {'start_index': 136, 'end_index': 198, 'title': 'Second Scenario/Task Session'}, {'start_index': 199, 'end_index': 300, 'title': 'Third Scenario/Task Session'}, {'start_index': 301, 'end_index': 312, 'title': 'Interview Session'}]}\n",
      "Transcript: Sarah\n",
      "Transcript: Sarah\n",
      "Transcript: Sarah\n",
      "Transcript: Sarah\n",
      "Transcript: Sarah\n",
      "{'segments': [{'start_index': 0, 'end_index': 63, 'title': 'Introduction'}, {'start_index': 64, 'end_index': 198, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 199, 'end_index': 257, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 258, 'end_index': 340, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 341, 'end_index': 356, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Advait\n",
      "Transcript: Advait\n",
      "Transcript: Advait\n",
      "Transcript: Advait\n",
      "Transcript: Advait\n",
      "{'segments': [{'start_index': 0, 'end_index': 46, 'title': 'Introduction'}, {'start_index': 47, 'end_index': 226, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 227, 'end_index': 413, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 414, 'end_index': 598, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 599, 'end_index': 626, 'title': 'Interview Session'}]}\n",
      "Transcript: Alex\n",
      "Transcript: Alex\n",
      "Transcript: Alex\n",
      "Transcript: Alex\n",
      "Transcript: Alex\n",
      "{'segments': [{'start_index': 0, 'end_index': 51, 'title': 'Introduction'}, {'start_index': 52, 'end_index': 170, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 171, 'end_index': 336, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 337, 'end_index': 412, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 413, 'end_index': 440, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Ezekiel\n",
      "Transcript: Ezekiel\n",
      "Transcript: Ezekiel\n",
      "Transcript: Ezekiel\n",
      "Transcript: Ezekiel\n",
      "{'segments': [{'start_index': 0, 'end_index': 61, 'title': 'Introduction'}, {'start_index': 64, 'end_index': 90, 'title': 'First Scenario/Task Session'}, {'start_index': 137, 'end_index': 176, 'title': 'Second Scenario/Task Session'}, {'start_index': 171, 'end_index': 201, 'title': 'Third Scenario/Task Session'}, {'start_index': 203, 'end_index': 302, 'title': 'Interview Session'}]}\n",
      "Transcript: Ian\n",
      "Transcript: Ian\n",
      "Transcript: Ian\n",
      "Transcript: Ian\n",
      "Transcript: Ian\n",
      "{'segments': [{'start_index': 0, 'end_index': 72, 'title': 'Introduction'}, {'start_index': 73, 'end_index': 71, 'title': 'First Scenario/Task Session'}, {'start_index': 263, 'end_index': 274, 'title': 'Second Scenario/Task Session'}, {'start_index': 346, 'end_index': 471, 'title': 'Third Scenario/Task Session'}, {'start_index': 472, 'end_index': 480, 'title': 'Interview Session'}]}\n",
      "Transcript: Shay\n",
      "Transcript: Shay\n",
      "Transcript: Shay\n",
      "Transcript: Shay\n",
      "Transcript: Shay\n",
      "{'segments': [{'start_index': 0, 'end_index': 46, 'title': 'Introduction'}, {'start_index': 48, 'end_index': 130, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 161, 'end_index': 198, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 161, 'end_index': 198, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 201, 'end_index': 265, 'title': 'Interview Session'}]}\n",
      "Transcript: Zoe\n",
      "Transcript: Zoe\n",
      "Transcript: Zoe\n",
      "Transcript: Zoe\n",
      "Transcript: Zoe\n",
      "{'segments': [{'start_index': 0, 'end_index': 66, 'title': 'Introduction'}, {'start_index': 67, 'end_index': 182, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 203, 'end_index': 256, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 258, 'end_index': 292, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 293, 'end_index': 376, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Jacob\n",
      "Transcript: Jacob\n",
      "Transcript: Jacob\n",
      "Transcript: Jacob\n",
      "Transcript: Jacob\n",
      "{'segments': [{'start_index': 1, 'end_index': 55, 'title': 'Introduction'}, {'start_index': 59, 'end_index': 89, 'title': 'First Scenario/Task Session'}, {'start_index': 179, 'end_index': 201, 'title': 'Second Scenario/Task Session'}, {'start_index': 256, 'end_index': 300, 'title': 'Third Scenario/Task Session'}, {'start_index': 360, 'end_index': 530, 'title': 'Interview Session'}]}\n",
      "Transcript: Maria\n",
      "Transcript: Maria\n",
      "Transcript: Maria\n",
      "Transcript: Maria\n",
      "Transcript: Maria\n",
      "{'segments': [{'start_index': 0, 'end_index': 57, 'title': 'Introduction'}, {'start_index': 58, 'end_index': 130, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 131, 'end_index': 202, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 203, 'end_index': 324, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 325, 'end_index': 336, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Hailey\n",
      "Transcript: Hailey\n",
      "Transcript: Hailey\n",
      "Transcript: Hailey\n",
      "Transcript: Hailey\n",
      "{'segments': [{'start_index': 0, 'end_index': 68, 'title': 'Introduction'}, {'start_index': 101, 'end_index': 130, 'title': 'First Scenario/Task Session'}, {'start_index': 182, 'end_index': 214, 'title': 'Second Scenario/Task Session'}, {'start_index': 224, 'end_index': 252, 'title': 'Third Scenario/Task Session'}, {'start_index': 260, 'end_index': 332, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Atharva\n",
      "Transcript: Atharva\n",
      "Transcript: Atharva\n",
      "Transcript: Atharva\n",
      "Transcript: Atharva\n",
      "{'segments': [{'start_index': 0, 'end_index': 66, 'title': 'Introduction'}, {'start_index': 67, 'end_index': 130, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 131, 'end_index': 153, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 154, 'end_index': 191, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 192, 'end_index': 266, 'title': 'Interview Session'}]}\n",
      "Transcript: Crosby\n",
      "Transcript: Crosby\n",
      "Transcript: Crosby\n",
      "Transcript: Crosby\n",
      "Transcript: Crosby\n",
      "{'segments': [{'start_index': 0, 'end_index': 68, 'title': 'Introduction'}, {'start_index': 69, 'end_index': 139, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 140, 'end_index': 276, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 277, 'end_index': 403, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 404, 'end_index': 420, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Ronny\n",
      "Transcript: Ronny\n",
      "Transcript: Ronny\n",
      "Transcript: Ronny\n",
      "Transcript: Ronny\n",
      "{'segments': [{'start_index': 0, 'end_index': 61, 'title': 'Introduction'}, {'start_index': 62, 'end_index': 165, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 166, 'end_index': 327, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 328, 'end_index': 392, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 393, 'end_index': 579, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Jian\n",
      "Transcript: Jian\n",
      "Transcript: Jian\n",
      "Transcript: Jian\n",
      "Transcript: Jian\n",
      "{'segments': [{'start_index': 0, 'end_index': 66, 'title': 'Introduction'}, {'start_index': 67, 'end_index': 326, 'title': 'Scenario 1 Task Session and Questionnaire'}, {'start_index': 327, 'end_index': 396, 'title': 'Scenario 2 Task Session and Questionnaire'}, {'start_index': 397, 'end_index': 488, 'title': 'Scenario 3 Task Session and Questionnaire'}, {'start_index': 489, 'end_index': 506, 'title': 'Final Interview Session'}]}\n",
      "Transcript: Jaylon\n",
      "Transcript: Jaylon\n",
      "Transcript: Jaylon\n",
      "Transcript: Jaylon\n",
      "Transcript: Jaylon\n",
      "{'segments': [{'start_index': 0, 'end_index': 71, 'title': 'Introduction'}, {'start_index': 72, 'end_index': 126, 'title': 'First Scenario/Task Session with Questionnaire'}, {'start_index': 127, 'end_index': 213, 'title': 'Second Scenario/Task Session with Questionnaire'}, {'start_index': 214, 'end_index': 282, 'title': 'Third Scenario/Task Session with Questionnaire'}, {'start_index': 283, 'end_index': 362, 'title': 'Interview Session'}]}\n",
      "Transcript: Ina\n",
      "Transcript: Ina\n",
      "Transcript: Ina\n",
      "Transcript: Ina\n",
      "Transcript: Ina\n"
     ]
    }
   ],
   "source": [
    "def parse_index(segment, messages):\n",
    "    start_index = segment[\"start_index\"]\n",
    "    end_index = segment[\"end_index\"]\n",
    "    segment_messages = messages[start_index:end_index + 1]\n",
    "    segment[\"messages\"] = segment_messages\n",
    "    return segment\n",
    "for name, messages, segmentation_response_str in responses:\n",
    "    segmentation_list = json.loads(segmentation_response_str)\n",
    "    print(segmentation_list)\n",
    "    # create directory segmented/{name}\n",
    "    os.makedirs(f\"segmented/{name}\", exist_ok=True)\n",
    "    for index, segment_response in enumerate(segmentation_list[\"segments\"]):\n",
    "        segmented_with_messages = parse_index(segment_response, messages)\n",
    "        print(f\"Transcript: {name}\")\n",
    "        with open(f\"segmented/{name}/{index}.json\", \"w\") as f:\n",
    "            json.dump(segmented_with_messages, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bd0d3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l4/65dfr4t56k1g5w3mbltb8tx40000gn/T/ipykernel_5408/2911804591.py:4: DeprecationWarning: The 'Client' class and the entire 'boxsdk' package is deprecated and will be removed in the future version. It is recommended to use 'box_sdk_gen' package and 'BoxClient' instead. \n",
      "  client = Client(oauth)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found shared folder: Shared Folder - AI-generated visualization User study data\n",
      "Shared link URL: https://ucdavis.app.box.com/s/xonzrpx7fo1rw7sfw3ov7x49yw7xy2cw/folder/350818283216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\"GET https://api.box.com/2.0/shared_items\" 404 158\n",
      "{'date': 'Mon, 08 Dec 2025 20:08:32 GMT', 'content-type': 'application/json', 'x-envoy-upstream-service-time': '102', 'box-request-id': '09adec2b28ed67638ed39316e7744d84b', 'cache-control': 'no-cache, no-store', 'strict-transport-security': 'max-age=31536000', 'via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'}\n",
      "{'code': '---ound',\n",
      " 'help_url': 'http://developers.box.com/docs/#errors',\n",
      " 'message': 'Not Found',\n",
      " 'request_id': 'v64atti844tp27g8',\n",
      " 'status': 404,\n",
      " 'type': 'error'}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error accessing shared folder: Message: Not Found\n",
      "Status: 404\n",
      "Code: not_found\n",
      "Request ID: v64atti844tp27g8\n",
      "Headers: {'date': 'Mon, 08 Dec 2025 20:08:32 GMT', 'content-type': 'application/json', 'x-envoy-upstream-service-time': '102', 'box-request-id': '09adec2b28ed67638ed39316e7744d84b', 'cache-control': 'no-cache, no-store', 'strict-transport-security': 'max-age=31536000', 'via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000', 'Transfer-Encoding': 'chunked'}\n",
      "URL: https://api.box.com/2.0/shared_items\n",
      "Method: GET\n",
      "Context Info: None\n",
      "You may need the password or different permissions\n"
     ]
    }
   ],
   "source": [
    "from boxsdk import Client, OAuth2\n",
    "token = \"OAafdBbbgjfAI70MV1QspEgxMbAS0dLH\"\n",
    "oauth = OAuth2(client_id=\"tw3cv4gyun93nwxwep4b4lxtbuppc9ub\", client_secret=\"E31ZiBvLuU0DGjJi7Is2arCu7r2YshQI\", access_token=token)\n",
    "client = Client(oauth)\n",
    "shared_link_url = \"https://ucdavis.app.box.com/s/xonzrpx7fo1rw7sfw3ov7x49yw7xy2cw/folder/350818283216\"  # Replace with actual URL\n",
    "items = client.folder('0').get_items()\n",
    "# If it's a web_link, you need to get the shared link URL first\n",
    "for item in items:\n",
    "    if item.type == 'web_link':\n",
    "        print(f\"Found shared folder: {item.name}\")\n",
    "        # Get the web link object\n",
    "        web_link = client.web_link(item.id).get()\n",
    "        print(f\"Shared link URL: {web_link.url}\")\n",
    "        \n",
    "        # If you have the actual shared link URL, you can access it like this:\n",
    "        # shared_link_url = web_link.url  # or use the direct URL if you know it\n",
    "        \n",
    "        # Create a client for the shared link\n",
    "        try:\n",
    "            # You may need to use the shared link to access the folder\n",
    "            shared_folder = client.get_shared_item(web_link.url)\n",
    "            shared_items = shared_folder.get_items()\n",
    "            \n",
    "            print(\"Items in shared folder:\")\n",
    "            for shared_item in shared_items:\n",
    "                print(f\"{shared_item.type}: {shared_item.name} (ID: {shared_item.id})\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing shared folder: {e}\")\n",
    "            print(\"You may need the password or different permissions\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyudao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
